## 1. Open a Twitter Account

The steps below will help you set up your twitter account to be able to access the live 1% stream.
1. Create a twitter account if you do not already have one.

2. Go to [https://apps.twitter.com](https://twitter.com) and log in with your twitter credentials.

3. Click "Create New App"

4. Fill out the form and agree to the terms. Put in a dummy website if you don't have one
you want to use.

5. At this point you will be prompted to attach a mobile phone number to your account if
you have not previously done so. Follow the instructions at the link provided. If you cannot complete this protocol, you may use the sample dataset in the repository, but we encourage you to connect to Twitter if possible so you can build your own applications.

6. On the next page, click the "Keys and Access Tokens" tab along the top, then scroll all the way down until you see the section "Your Access Token"

7. Click the button "Create My Access Token". 

8. Copy these four values into the file mytwitterstream.py. These values are your "Consumer Key (API Key)", your "Consumer Secret (API Secret)", your "Access token" and your "Access token secret". All four should now be visible on the "Keys and Access Tokens" page. Open mytwitterstream.py and set the variables corresponding to the api key, api secret, access token, and access secret.


## Testing Access
Run the following and make sure you see data flowing and that no errors occur.

$ python twitterstream.py > output.txt

This command pipes the output to a file. Stop the program with Ctrl-C, but wait at least 3 minutes for data to accumulate. 

## What to turn in:
The first 20 lines of the twitter data downloaded from the web.

You can save the first 20 lines to a file problem_1_submission.txt by using the following command:

$ head -n 20 output.txt > problem_1_submission.txt

## 2. Derive sentiment of each tweet

The file tweet_sentiment.py accepts two arguments on the command line: a sentiment file and a tweet file (like the one generated in para 1 above). The program may be run like this:

$ python mytweet_sentiment.py AFINN-111.txt output.txt

The file AFINN-111.txt contains a list of pre-computed sentiment scores. Each line in the file contains a word or phrase followed by a sentiment score. Each word or phrase that is found in a tweet but not found in AFINN-111.txt should be given a sentiment score of 0. See the file AFINN- README.txt for more information.

The data in the tweet file in 1 above is represented as JSON, which stands for JavaScript Object Notation. It is a simple format for representing nested structures of data- lists of lists of dictionaries of lists of .....

Each line of output.txt represents a streaming message. Most, but not all, will be tweets. 

The script should print to stdout the sentiment of each tweet in the file, one numeric sentiment score per line. The first score should correspond to the first tweet, the second score should correspond to the second tweet, and so on. If you sort the scores, they won't match up. If you sort the tweets, they won't match up. If you put the tweets into a dictionary, the order will not be preserved. Once again: The nth line of the file should contain only a single number that represents the score of the nth tweet in the input file!

This is real-world data, and it can be messy!

## What to turn in:
The file mytweet_sentiment.py after you've verified that it returns the correct answers.

## 3 Derive the sentiment of new terms

In this part you will be creating a script that computes the sentiment for the terms that do not appear in the file AFINN-111.txt.

The script should print output to stdout. Each line of output should contain a term, followed by a space, followed by the sentiment. That is, each line should be in the format <term:string> <sentiment:float>

For example, if you have the pair ("foo", 103.256) in Python, it should appear in the output as:
foo 103.256

## What to turn in: 
The file term_sentiment.py


## 4 Compute Term Frequency

A Python script myfrequency.py to compute the term frequency histogram of the livestream data harvested from Problem 1.

The frequency of a term can be calculated as [# of occurrences of the term in all tweets]/[# of occurrences of all terms in all tweets]

The script will be run from the command line like this:
$ python frequency.py <tweet_file>

Assume the tweet file contains data formatted the same way as the livestream data.

The script should print output to stdout. Each line of output should contain a term, followed by a space, followed by the frequency of that term in the entire file. There should be one line per unique term in the entire file. Even if 25 tweets contain the word lol, the term lol should only appear once in your output (and the frequency will be at least 25!) Each line should be in the format <term:string> <frequency:float>
For example, if you have the pair (bar, 0.1245) in Python it should appear in the output as:
bar 0.1245

## What to turn in: 
The file myfrequency.py

## 6 Which State is happiest?

A Python script myhappiest_state.py that returns the name of the happiest state as a string.
Your script happiest_state.py should take a file of tweets as input. It will be called from the command line like this:
$ python myhappiest_state.py <sentiment_file> <tweet_file>

The file AFINN-111.txt contains a list of pre-computed sentiment score.

Assume the tweet file contains data formatted the same way as the livestream data.

Note: Not every tweet will have a text field --- again, real data is dirty! Be prepared to debug, and feel free to throw out tweets that your code can't handle to get something working. For example, you might choose to ignore all non-English tweets.

The script should print the two letter state abbreviation of the state with the highest average tweet sentiment to stdout.

Note that you may need a lot of tweets in order to get enough tweets with location data. Let the live stream run for a while if you wish.

## What to turn in: 
The file happiest_state.py

## 6 Top ten hash tags

A Python script mytop_ten.py that computes the ten most frequently occurring hashtags from the data you gathered in Problem 1.

Your script will be run from the command line like this:
$ python top_ten.py <tweet_file>

You should assume the tweet file contains data formatted the same way as the livestream data.

Each line of output should contain a hashtag, followed by a space, followed by the frequency of that hashtag in the entire file. 

There should be one line per unique hashtag in the entire file. Each line should be in the format <hashtag:string> <frequency:float>

For example, if you have the pair (bar, 30) in Python it should appear in the output as: bar 30

## What to turn in: 
the file mytop_ten.py

